[ { "title": "[Git] branch의 이해와 사용(미완성)", "url": "/posts/git-04/", "categories": "Git", "tags": "Git, Github", "date": "2021-12-04 00:00:00 +0900", "snippet": "코드를 복사하고 나서 원래 코드와는 상관없이 독립적으로 개발을 할 수 있게 만드는 것이 “브랜치” 입니다.Git의 최고의 장점이라고 말하는 “브랜치”에 대해 알아볼까요?Gti branch란?모든 형상관리 시스템은 브랜치를 지원합니다. 팀 단위로 개발을 하다보면 각자 독립적인 공간에서 개발을 진행해야 서로의 소스코드가 섞이거나 충돌되는 것을 방지할 수 있습니다.이런 이유로 브랜치 모델이 Git의 최고의 장점이라고 말합니다. Git branch는 매우 가벼우며 순식간에 브랜치를 새로 만들고 사이를 이동할 수 있습니다.또한, Git은 branch를 만들어서 작업하고 merge 하는 방법을 권장합니다." }, { "title": "[Git] Github 원격저장소와 로컬저장소 연동하기", "url": "/posts/git-03/", "categories": "Git", "tags": "Git, Github", "date": "2021-12-03 00:00:00 +0900", "snippet": "깃허브 원격저장소와 로컬저장소 연동을 머리속에서만 알고있었고, git 관련 명령어도 필요할 때마다 구글링으로 찾아서 처리했었는데…날잡고 정리해서 내것으로 만들어야지 생각만하다가 오늘 정리하기로 맘먹었다.오늘은! 로컬 저장소(workspace)를 깃허브 원격저장소에 연동하는 방법에 대해 포스팅 해보겠습니다.참고로, git이 설치가 안되신분들은 git을 설치하고 오시기 바랍니다.로컬 저장소 생성 Git Bash 실행 본인이 작업할 로컬 workspace(폴더)를 생성합니다. 생성할 위치 이동 + git_test라는 이름의 폴더 생성합니다. seong@DESKTOP-O5CIEJV MINGW64 ~ $ cd E:/project &amp;amp;&amp;amp; mkdir git_test 생성한 workspace(폴더) git_test에서 git 저장소를 생성합니다. seong@DESKTOP-O5CIEJV MINGW64 /e/project $ cd git_test/ seong@DESKTOP-O5CIEJV MINGW64 /e/project/git_test $ git init Initialized empty Git repository in E:/project/git_test/.git/ 파일 생성 seong@DESKTOP-O5CIEJV MINGW64 /e/project/git_test (master) $ vi test.py git status로 상태를 확인해보면 생성된 test.py 파일을 git에 추가할 수 있다고 나옵니다. seong@DESKTOP-O5CIEJV MINGW64 /e/project/git_test (master) $ git status On branch master No commits yet Untracked files: (use &quot;git add &amp;lt;file&amp;gt;...&quot; to include in what will be committed) test.py nothing added to commit but untracked files present (use &quot;git add&quot; to track) git 저장소에 추가 No commits yet : 아직 커밋을 하지 않다고 나옵니다. seong@DESKTOP-O5CIEJV MINGW64 /e/project/git_test (master) $ git add test.py seong@DESKTOP-O5CIEJV MINGW64 /e/project/git_test (master) $ git status On branch master No commits yet Changes to be committed: (use &quot;git rm --cached &amp;lt;file&amp;gt;...&quot; to unstage) new file: test.py git commit -m &quot;test commit add test.py&quot; &amp;lt;- commit message seong@DESKTOP-O5CIEJV MINGW64 /e/project/git_test (master) $ git commit -m &quot;test commit add test.py&quot; [master (root-commit) fc4e43a] test commit add test.py 1 file changed, 0 insertions(+), 0 deletions(-) create mode 100644 test.py 원격 저장소 생성 및 연동 github repository 생성합니다. code -&amp;gt; HTTPS 누르시면 URL이 나오는데 COPY합니다. git remote, 로컬 저장소와 원격 저장소를 연동합니다. git remote add [원격저장소별칭] [원격저장소URL] seong@DESKTOP-O5CIEJV MINGW64 /e/project/git_test (master) $ git remote add origin https://github.com/s-seongsik/github_test.git remote 연결을 확인합니다. seong@DESKTOP-O5CIEJV MINGW64 /e/project/git_test (master) $ git remote origin $ git remote -v origin https://github.com/s-seongsik/github_test.git (fetch) origin https://github.com/s-seongsik/github_test.git (push) git push [원격저장소별칭] [로컬브랜치이름] --all 을 붙이면 로컬의 모든 브랜치를 push 합니다.```console # 로컬브랜치 확인 seong@DESKTOP-O5CIEJV MINGW64 /e/project/git_test (master) $ git branch master # push seong@DESKTOP-O5CIEJV MINGW64 /e/project/git_test (master) $ git push origin master Enumerating objects: 3, done. Counting objects: 100% (3/3), done. Writing objects: 100% (3/3), 230 bytes | 230.00 KiB/s, done. Total 3 (delta 0), reused 0 (delta 0) remote: remote: Create a pull request for ‘master’ on GitHub by visiting: remote: https://github.com/s-seongsik/github_test/pull/new/master remote: To https://github.com/s-seongsik/github_test.git [new branch] master -&amp;gt; master``` 원격저장소를 보면 연동된 master 로컬브랜치에 test.py가 생성된것을 볼 수 있습니다. 파일 수정해보기 test.py를 수정합니다. git status로 상태확인 modified : test.py &amp;lt;-라는 문구에서 변경 확인이 가능합니다. seong@DESKTOP-O5CIEJV MINGW64 /e/project/git_test (master) $ git status On branch master Changes to be committed: (use &quot;git restore --staged &amp;lt;file&amp;gt;...&quot; to unstage) modified: test.py 위에서 배운대로 git add -&amp;gt; git commit -&amp;gt; git push 를 진행합니다. tip) git add . 을 하시면 변경된 모든 것을 add 합니다. seong@DESKTOP-O5CIEJV MINGW64 /e/project/git_test (master) $ git add test.py seong@DESKTOP-O5CIEJV MINGW64 /e/project/git_test (master) $ git commit -m &quot;modify test.py&quot; [master 5a43c8b] modify test.py 1 file changed, 2 insertions(+) seong@DESKTOP-O5CIEJV MINGW64 /e/project/git_test (master) $ git push origin master Enumerating objects: 5, done. Counting objects: 100% (5/5), done. Writing objects: 100% (3/3), 272 bytes | 272.00 KiB/s, done. Total 3 (delta 0), reused 0 (delta 0) To https://github.com/s-seongsik/github_test c81e115..5a43c8b master -&amp;gt; master test.py 내용이 변경된 것을 확인할 수 있습니다.끝으로로컬저장소와 원격저장소 연동하는 과정을 정리하면서 좀더 github와 git를 깊게 공부하고 싶은 욕심이 생겼습니다.기회가 되면 git으로 협업하는 방법과 git의 원리 및 용어정리 대해 포스팅 해보겠습니다. 감사합니다." }, { "title": "[Git] Git 이해하기", "url": "/posts/git-01/", "categories": "Git", "tags": "Git, Github", "date": "2021-12-02 00:00:00 +0900", "snippet": "Git과 Github를 활용하여 버전관리를 하는거에 익숙하지만, Git의 원리에 대해 묻는다면 정확하게 답변할 수 없습니다.이번 포스팅은 Git의 배경과 원리를 이해하여 정리해보는 시간을 갖게 되었습니다.목차는 아래와 같이 진행합니다. 버전 관리란? Git의 배경 Git의 원리버전 관리란?버전 관리 시스템이란? 파일 변화를 시간에 따라 기록했다가 나중에 특정 시점의 버전을 다시 꺼내올 수 있는 시스템입니다. 버전 관리 방법은 크게 3가지로 나뉩니다.로컬 버전 관리 디렉토리로 파일을 복사하는 방법 이 방법은 가장 간단하므로, 많은 사람들이 사용한다. 하지만, 작업 디렉토리를 삭제하거나, 실수로 인한 수정 및 복사가 발생할 수 있다는 단점이 있다.중앙집중식 버전 관리(CVCS) CVCS는 파일을 관리하는 중앙서버가 별도로 있고, 클라이언트가 중앙 서버에서 파일을 받아서 사용(Checkout)합니다. CVCS는 모두 누가 무엇을 하고 있는지 알 수 있다는 장점이 있습니다. 치명적인 결점은, 중앙 서버에 문제가 발생했을 때 그 시간동안 아무도 다른 사람과 협업할 수 없으며 사람들이 하는 일을 백업할 방법도 없습니다. 그리고, 중앙 데이터베이스가 있는 하드디스크에 문제가 생기면 프로젝트의 모든 히스토리를 잃습니다. 즉, 중앙서버가 문제가 생기면 모든 것을 잃습니다. 대표적으로 SVN이 있습니다.분산 버전 관리 시스템(DVCS) Git이 DVCS에 속하며, DVCS에서의 클라이언트는 단순히 파일의 마지막 스냅샷을 Checkout하지 않습니다. 그냥 저장소를 히스토리와 더불어 전부 복제합니다. 서버에 문제가 생겨도 이 복제물로 다시 작업을 할 수 있습니다. 클라이언트 중에서 아무거나 골라도 서버를 복원할 수 있습니다. clone은 모든 데이터를 가진 진정한 백업입니다. DVCS 환경에서는 리모트 저장소가 존재합니다. 리모트 저장소는 많을 수도 있습니다. 따라서 동시에 다양한 그룹과 다양한 방법으로 협업이 가능합니다.Git의 배경Linux 커널은 굉장히 규모가 큰 오픈소스 프로젝트다. Linux 커널의 삶 대부분은(1991–2002) Patch와 단순 압축 파일로만 관리했다. 2002년에 드디어 Linux 커널은 BitKeeper라고 불리는 상용 DVCS를 사용하기 시작했다. 2005년에 커뮤니티가 만드는 Linux 커널과 이익을 추구하는 회사가 개발한 BitKeeper의 관계는 틀어졌다. BitKeeper의 무료 사용이 재고된 것이다. 이 사건은 Linux 개발 커뮤니티(특히 Linux 창시자 Linus Torvalds)가 자체 도구를 만드는 계기가 됐다. Git은 BitKeeper를 사용하면서 배운 교훈을 기초로 아래와 같은 목표를 세웠다. 빠른 속도 단순한 구조 비선형적인 개발(수천 개의 동시 다발적인 브랜치) 완벽한 분산 Linux 커널 같은 대형 프로젝트에도 유용할 것(속도나 데이터 크기 면에서)Git의 원리Git을 사용하기 전에 Git의 원리를 먼저 이해하는 것이 중요할 것 같다. 기존의 VCS, CVCS와의 차이점은 무엇인지 알아보자.스냅샷Git이 다른 버전 관리 도구와 다른 점은 스냅샷(snapshot) 방식을 이용한다는 것입니다. CVS, Subversion, Perforce, Bazaar 등의 시스템들은 각 파일의 변화를 시간순으로 관리하면서 파일들의 집합을 관리합니다. 쉽게 말해 이전에 파일을 복사하여 관리합니다. 파일을 복사하는 방식으로 수정본을 관리하게 되면 같은 내용을 반복 저장하기 때문에 용량을 많이 차지합니다. 또 수정된 부분들을 일일이 찾아야 하므로 검색할 때 불편합니다.Git은 이러한 시스템적인 단점을 보완하고자 변경된 파일 전체를 저장하지 않고, 파일에서 변경된 부분만 찾아 수정된 내용만 저장합니다. 마치 변화된 부분만 찾아 사진을 찍는 것과 같다고 해서 스냅샷 방식이라고 말합니다.스냅샷 방식은 커밋을 기반으로 사진을 찍습니다. 커밋은 파일 변화를 깃 저장소에 영구적으로 기록합니다. 또한, 빠르게 버전의 차이점을 처리하고, 용량을 적게 사용합니다.거의 모든 명령은 로컬에서 실행거의 모든 명령이 로컬의 파일과 데이터만 사용하기 때문에 네트워크에 영향을 받지 않습니다. 이는 네트워크 속도에 영향을 받는 CVCS보다 월등히 높은 속도를 자랑합니다.Git은 프로젝트의 모든 히스토리가 로컬 디스크에 있기 때문에 모든 명령이 순식간에 실행됩니다. Git은 프로젝트의 히스토리를 서버없이 조회합니다. 그냥 로컬 데이터베이스에서 읽기 때문에 속도가 빠릅니다. Git은 현재버전과 예전버전 상태를 비교할 때 로컬에서 찾기 때문에 리모트에 있는 서버에 접근할 필요가 없습니다. 즉, 오프라인 상태거나, VPN이 없어거나, 네트워크가 안되도 막힘 없이 일 할 수 있는 장점을 가지고 있습니다.무결성Git은 데이터를 저장하기 전에 항상 체크섬을 구하고 그 체그섬으로 데이터를 관리합니다. 체크섬이란 Git에서 사용하는 가장 기본적인 데이터 단위이자 Git의 기본 철학입니다.Git 없이는 체크섬을 다룰 수 없어서 파일의 상태도 알 수 없고, 데이터를 잃어버릴 수도 없습니다.Git은 SHA-1 해시를 사용하여 체크섬을 생성합니다. 생성한 체크섬은 40자 길이의 16진수 문자열입니다. 파일의 내용이나, 디렉토리 구조를 이용하여 체크섬을 생성합니다.(체크섬 예시 : 24b9da6552252987aa493b52f8696cd6d3b00373)Git은 모든 것을 해시로 식별합니다. 그렇기 때문에 Git은 파일을 이름으로 저장하지 않고 해시로 저장합니다.Git은 데이터를 추가할 뿐이다Git은 어떤 작업을 하던 Git 로컬 데이터베이스에 데이터를 추가합니다. 하지만, 되돌리거나 삭제할 방법이 없습니다. 또한 커밋하지 않으면 변경사항을 잃어버릴 수 있습니다.하지만, 스냅샷을 커밋하고 나면 데이터를 잃어버리기 어렵습니다.Git의 3가지 상태Git은 파일을 Committed, Modified, Staged 이렇게 3가지 상태로만 관리합니다. Committed는 데이터가 로컬 데이터베이스에 안전하게 저장됐다는 것을 말합니다. Modified는 수정한 파일을 아직 로컬 데이터베이스에 커밋하지 않은 것을 말합니다. Staged는 현재 수정한 파일을 곧 커밋할 것이라고 표시한 상태를 의미합니다.Git 프로젝트의 3가지 단계Git 프로젝트는 아래와 같은 3가지 단계로 나뉩니다. Git 디렉토리 Git 디렉토리가 Git의 핵심입니다. 다른 컴퓨터에 있는 저장소를 clone할 때 Git 디렉토리가 생성됩니다. Git 디렉토리는 프로젝트의 메타데이터와 객체 데이터베이스를 저장하는 곳을 말합니다. Git 디렉토리는 현재 작업하는 디스크에 있으며, 그 디렉토리 안에 압축된 데이터베이스에서 파일을 가져와 Working 디렉토리를 생성합니다. working 디렉토리 Working 디렉토리는 특정 버전을 Checkout한 것입니다. Git 디렉토리에서 생성됩니다. Staging Area Staging Area는 Git 디렉토리 안에 있습니다. Working 디렉토리에서 파일을 수정하면 Staging Area로 추가됩니다. 단순한 파일이며, 곧 커밋할 파일에 대한 정보를 저장합니다. Git 디렉토리에 있는 파일들은 Committed된 상태입니다. 파일을 수정하고 Staging Area에 추가했으면, Staged 상태입니다. Checkout 하고 수정했지만, 아직 Staging Area에 추가하지 않으면 Modified 상태입니다.Git의 3가지 상태 실습해보기 test branch에 test.py라는 파일이 있습니다. test.py을 수정합니다. Git 상태 확인 Changes not staged for commit: 에 있다고 합니다. 즉, 아직 staged 상태가 아니라는 것입니다. modified: test.py 라고 되어있는 것을 확인할 수 있습니다. $ git status On branch test Your branch is up to date with &#39;origin/test&#39;. Changes not staged for commit: (use &quot;git add &amp;lt;file&amp;gt;...&quot; to update what will be committed) (use &quot;git restore &amp;lt;file&amp;gt;...&quot; to discard changes in working directory) modified: test.py Untracked files: (use &quot;git add &amp;lt;file&amp;gt;...&quot; to include in what will be committed) sample_01/ no changes added to commit (use &quot;git add&quot; and/or &quot;git commit -a&quot;) Staging Area에 추가하기 staged 상태로 추가하기 위해서는 git add로 Staging Area에 추가해줘야 합니다. git add test.py를 해주고 git status로 상태를 확인해 보니, Changes to be committed: 라고 되어있습니다. 즉, Staged 상태로 변경되었습니다. $ git add test.py $ git status On branch test Your branch is up to date with &#39;origin/test&#39;. Changes to be committed: (use &quot;git restore --staged &amp;lt;file&amp;gt;...&quot; to unstage) modified: test.py Untracked files: (use &quot;git add &amp;lt;file&amp;gt;...&quot; to include in what will be committed) sample_01/ commit 하기 git commit -m “test.py” 으로 커밋을 실행합니다. git status에 없는 것을 확인할 수 있습니다. git log를 통해 commit history를 확인할 수 있습니다. " }, { "title": "[python] Windows 스케줄러 기능으로 파이썬 스크립트 작업 등록하기", "url": "/posts/python-scheduler-windows/", "categories": "Python", "tags": "Python, Windows, Linux, Cron, Crontab, Job Scheduler", "date": "2021-12-01 00:00:00 +0900", "snippet": "오늘은 Python 스크립트를 windows 작업 스케줄러에 등록하는 방법에 대해 포스팅 해보겠습니다~이전에 Linux cron과 python apscheduler에 대해 포스팅을 하고나서 windows 에서 제공하는 작업 스케줄러에 대해 포스팅 해야겠다고 생각했습니다.Linux cron과 apscheduler에 대해 궁굼하신 분들은 밑의 링크를 눌러세요![python] Apscheduler vs Cron Job1. 윈도우 작업 스케줄러 실행2. 윈도우 작업 등록 오른쪽 상단에 [작업 만들기]를 클릭 이름에는 작업 등록에 사용될 이름을 기입 관리자 권한으로 실행하는 경우가 많으므로, 가장 높은 수준의 권한으로 실행을 체크 (필요없으면 체크를 안하셔도 됩니다) [트리거] 탭을 누르시면 작업 주기를 설정할 수 있는 창이 뜹니다. 설정에서 한 번 (최초 1회), 매일, 매주, 매월 중 본인에 맞는 주기를 선택 시작에서 작업 시작시간을 선택 매주 월~금 오후 11:25:55 시간에 파이썬 스크립트를 돌린다고 가정하고 선택 [동작] 탭을 누르시면 실행시킬 프로그램/스크립트를 등록할 수 있습니다 프로그램/스크립트에는 python이 깔려있는 경로 설치경로\\python.exe를 등록해줍니다(ex. D:\\anaconda3\\python.exe) python으로 실행해야 하므로 python.exe를 등록해야 합니다. 만약, python 설치경로를 모르신다면 cmd -&amp;gt; where python을 입력하면 위치를 알 수 있습니다 저같은 경우에는 가상환경을 따로 만들었고 해당 경로의 python.exe를 입력 인수 추가(옵션)에는 실행시킬 python 스크립트의 절대 경로를 입력 시작 위치(옵션)에는 python 스크립트의 폴더 경로만 입력 [조건] 탭을 누르시면 작업 실행 여부를 결정할 수 있는 트리거들을 설정할 수 있습니다 만약 데스크탑이면 크게 바뀔 건 없지만, 노트북이라면 전원 &amp;gt; [컴퓨터의 AC 전원이 켜져 있는 경우에만 작업 시작] 을 해제 노트북은 배터리로 전원을 키기때문에 작업이 등록되어있어도 실행이 안되는 경우가 생깁니다. 작업 실행 여부에 영향을 미치는 조건을 배제시켜 무조건 돌아가게 만들 수 있습니다. [설정] 탭을 누르시면 작업의 동작에 영향을 주는 추가 설정을 할 수 있습니다 작업 스케줄러가 제대로 동작 안했을 때 후 처리를 어떻게 할 것인지 설정 후 처리 요구사항이 있지 않다면, 건들지 않고 확인 3. 마무리 linux의 cron과 비슷하게 OS 플랫폼에서 제공하는 기능이다보니 간편하게 스케줄러 작업을 등록할 수 있었습니다. 앞으로 Linux, windows 환경에서 스케줄러 작업을 해야할 상황이 생기면 요긴하게 사용할 것 같습니다." }, { "title": "[python] Apscheduler vs Cron Job", "url": "/posts/python-scheduler/", "categories": "Python", "tags": "Python, Windows, Linux, Cron, Crontab, Job Scheduler", "date": "2021-11-30 00:00:00 +0900", "snippet": "python 개발일을 하다보면 스케줄러 프로그램을 만들일이 생기는데, python에서 스케줄러 라이브러리와 linux에서 제공하는 스케줄링 기능에 대해 알아보고어떤 상황에 무엇을 사용해야 좋을지 포스팅 해보겠습니다.APSchedulerAdvanced Python Schedule의 약자로 python code가 한 번 또는 주기적으로 실행되도록 예약할 수 있는 python libary cron Daemon 이나 windows 작업 스케줄러와 같은 플랫폼별 스케줄러에 대체품으로 사용scheduling 방식 Cron 스타일 스케줄링 Interval(간격) 기간 실행 일회성 지연 실행같이 사용할 수 있는 시스템 메모리 (default) SQLAlchemy 몽고DB 레디스 RethinkDB 주키퍼 Flask Djangoscheduling 선택가장 많이 사용되는 2가지를 소개하겠습니다. BlockingScheduler: 스케줄러가 프로세스에서 실행 중인 유일한 경우에 사용 BackgroundScheduler: 프레임워크를 사용하지 않고 스케줄러가 애플리케이션 내부의 백그라운드에서 실행되기를 원할 때 사용사용방법pip를 사용하여 설치 보통 작업하는 가상환경에 설치 $ pip install apschedulerBlockingScheduler import time from apscheduler.schedulers.blocking import BlockingScheduler sched = BlockingScheduler() # 3초마다 실행 @sched.scheduled_job(&#39;interval&#39;, seconds=3, id=&#39;test_1&#39;) def test1(): print(f&#39;test1 : {time.strftime(&quot;%H:%M:%S&quot;)}&#39;) print(&#39;job Start&#39;) sched.start() print(&#39;job end&#39;) job Start test1 : 10:13:44 test1 : 10:13:47 test1 : 10:13:50 test1 : 10:13:53 test1 : 10:13:56 ...BlockingScheduler 스케줄러를 사용하게되면 sched.start()에 block이 걸려 해당 프로세스만 계속해서 유지하고 있기 떄문에print(‘job end’)가 실행되지 않습니다.BackgroundScheduler import time from apscheduler.schedulers.background import BackgroundScheduler sched = BackgroundScheduler() # 3초마다 실행 @sched.scheduled_job(&#39;interval&#39;, seconds=3, id=&#39;test_1&#39;) def test1(): print(f&#39;test1 : {time.strftime(&quot;%H:%M:%S&quot;)}&#39;) print(&#39;job Start&#39;) sched.start() print(&#39;job end&#39;) job Start job endBackgroundScheduler 스케줄러를 사용하게 되면 sched.start() 3초를 기다리지않고 바로 프로그램이 종료됩니다. 백그라운드로 돌아가기 때문입니다.sched.start() 함수 다음에도 다른 작업을 하기 위해서는 BackgroundScheduler를 사용해야 합니다. import time from apscheduler.schedulers.background import BackgroundScheduler sched = BackgroundScheduler() # 3초마다 실행 @sched.scheduled_job(&#39;interval&#39;, seconds=3, id=&#39;test_1&#39;) def test1(): print(f&#39;test1 : {time.strftime(&quot;%H:%M:%S&quot;)}&#39;) print(&#39;job Start&#39;) sched.start() print(&#39;job end&#39;) while True: time.sleep(1)프로그램을 계속해서 유지하기 위해서는 while문 하나만 넣어주면 됩니다. job Start job end test1 : 10:46:23 test1 : 10:46:26 test1 : 10:46:29 test1 : 10:46:32 test1 : 10:46:35 ...Crontab유닉스/리눅스에서 특정 시간에 특정 작업을 하는 데몬을 Cron이라고 합니다. Cron에서 어떤 명령을 언제 수행하도록 만든 리스트를 Crontab 이라고 합니다.Crontab을 특정 파일을 등록해서 스케줄링 작업한다고 이해한다기 보다, 리눅스 명령어(프로그램)를 스케줄링 한다고 이해하시는게 더 정확한 표현입니다.Crontab 등록, 조회, 삭제리눅스 쉘에서 아래의 명령어를 입력하면 Crontab을 등록할 수 있습니다. $ crontab -e리눅스 쉘에서 아래의 명령어를 입력하면 동록된 Crontab 리스트를 조회할 수 있습니다. $ crontab -l리눅스 쉘에서 아래의 명령어를 입력하면 동록된 Crontab 리스트를 삭제할 수 있습니다. $ crontab -d리눅스 쉘에서 아래의 명령어를 입력하면 동록된 Crontab 리스트를 전체 삭제할 수 있습니다. $ crontab -rCrontab 설정 * 분(0-59)　　　　　　* 시간(0-23)　　　　　　* 일(1-31)　　　　　　* 월(1-12)　　　　　　* 요일(0-6, 일요일=0) # 1분 마다 실행 * * * * * path/test.sh # 10분 마다 실행 */10 * * * * path/test.sh # 1시간 마다 실행 0 * * * * path/test.sh # 2시간 마다 실행 0 */2 * * * path/test.sh # 매일 매시간 10분, 20분, 30분에 test.sh 를 실행 10,20,30 * * * * path/test.sh # 06~12시내 1시간 마다 실행 00 06-12 * * * path/test.sh # 매일 15시 0분부터 30분까지 매분 tesh.sh를 실행 0-30 15 * * * path/tesh.sh # 특정 시간 마다 실행 / 매주 월요일 15시 30분 마다 실행 30 15 * * 1 path/test.shCrontab 주의사항 실행 파일 path 설정, cron은 보안문제로 개인 설정 파일을 참조하지 않습니다. 그러므로 실행 프로그램은 /bin/…/… 같은 일반 경로가 있어야 cron에 제대로 반영됩니다. crontab 등록시 한줄에 하나씩 등록해야 합니다. #를 사용하여 주석을 사용할 수 있습니다. crontab이 실제로 실행됐는지 확인할 수 있는 방법이 없기 때문에 로그를 남겨야 합니다. 로그를 남기는 방법은 # &amp;gt; path/crontab.log 2&amp;gt;%1 입력한 path에 crontab.log라는 파일이 생성되며 실행될 때마다 log를 저장합니다. * * * * * path/test.sh &amp;gt; path/crontab.log 2&amp;gt;%1 crontab 변경 후에는 반드시 cron을 다시 실행해야 변경 내용이 제대로 반영됩니다.apscheduler vs cron job이번 포스트의 핵심이죠, 저와 비슷한 상황의 사용자에게 도움이 되었으면 좋겠습니다.어떤 기능을 사용할지 고르기전에 어떤 상황인지를 설명드려야겠죠? 상황1 : python script 실행 상황2 : 매일 특정 시간이 되면 실행 (1일 - 1회)만약 python의 apscheduler를 매일 특정시간에 구동시켜야한다면, 세션이 종료되더라도 돌아갈 수 있게 만들어야합니다.예를들어, linux의 nohup과 &amp;amp;(백그라운드)를 사용해서 세션이 종료되더라도 백그라운드로 python script를 돌릴 수 있습니다.하지만, 하루에 한번만 실행하면 되는 조건에서 불필요한 전력, 메모리, cpu 등의 자원을 소비할 필요가 없다고 생각됩니다.반대로, apscheduler는 이미 작성된 code내에서 커스텀이 가능합니다.예를들어 기능마다 실행되야될 시간이 다르다면, 혹은 다른 시스템과의 협업으로 많은 요구사항이 필요하다면 apscheduler를 사용하는게 좋습니다. import time from apscheduler.schedulers.background import BackgroundScheduler sched = BackgroundScheduler() # 매일 13시 30분에 실행 @sched.scheduled_job(&#39;cron&#39;, hour=&#39;13&#39;, minute=&#39;30&#39;, id=&#39;job_1&#39;) def job1(): print(&#39;job1&#39;) # 매일 15시 50분에 실행 @sched.scheduled_job(&#39;cron&#39;, hour=&#39;13&#39;, minute=&#39;50&#39;, id=&#39;job_2&#39;) def job2(): print(&#39;job2&#39;) # 매일 17시 10분에 실행 @sched.scheduled_job(&#39;cron&#39;, hour=&#39;17&#39;, minute=&#39;10&#39;, id=&#39;job_3&#39;) def job3(): print(&#39;job3&#39;) while True: time.sleep(1)crontab은 단순히 명령어(프로그램)를 등록하는 것이기 때문에 code내 커스텀이 불가능합니다.결론 자원의 관점, 요구사항이 특정 시간에만 스크립트가 실행되어야 한다(요구사항이 단순) -&amp;gt; crontab 기능의 관점, 기능별로 스케줄 시간이 달라야 하거나, 요구사항이 복잡하다 -&amp;gt; apscheduler" }, { "title": "네이버 클라우드 서버에 putty, filezila 접속하기", "url": "/posts/cloud/", "categories": "Cloud, Naver Cloud", "tags": "cloud", "date": "2021-11-04 00:00:00 +0900", "snippet": "현재 플랫폼 서비스를 제공하기 위해 고객사에 WAS Server, DB Server를 납품하여 APP과 DB를 관리 및 운영하고있습니다. 이런 방식은 온프레미스 인프라가 증가함에 따라 관리 포인트도 증가하게 됩니다.계속해서, 서비스 환경의 패러다임이 Cloud로 변화되면서 IT산업은 클라우드 기술이 필수 불가결하게 됐다고 생각합니다.따라서, 최근 회사에서도 클라우드 기술에 관심을 갖고 있으며, 이번에 클라우드 기반 docker 컨테이너로 FastAPI기반 REST-API 서버를 구축하게 되었습니다.이번 POST에서는 전반적인 흐름으로 cloud + docker 컨테이너 환경에서 python app을 배포 및 운영하는 방법에 대해 다뤄보도록 하겠습니다.1. Naver Cloud 포트포워딩 설정 server 서비스를 구입을 하면 왼편 Bookmarks 탭에서 Server가 생긴 것을 확인할 수 있습니다. Server 탭을 누르고 들어가면 아래와 같은 화면이 뜨는데, +서버생성 버튼을 눌러 간편하게 원하는 서버를 생성할 수 있습니다.저는 이미 생성되있는 서버에 배포할 예정입니다. (서버 생성시 인증키 설정을 하게 되는데 인증키는 서버에 접속할 계정생성에 사용됩니다.) 생성된 Server row을 클릭하면 빨간색 표시처럼 포트 포워딩 설정 버튼을 클릭할 수 있도록 변경됩니다. 클릭하게 되면 팝업창이 뜨는데 여기서 외부 포트, 내부 포트를 설정할 수 있습니다.외부포트는 외부에서 해당 클라우드로 접속하기 위한 포트 설정입니다. 저는 putty나 filezila로 ssh로 접속할 때 사용합니다. 이렇게 외부포트로 들어온 접속자를 설정한 내부포트로 연결됩니다. 마지막으로 cloud 서버에 접속하기 위해 서버생성 때 설정한 인증키 인증을 통해서 관리자 비밀번호를 확인한다. (naver cloud 설명서에 자세히 있으니 참고.) 자! 여기까지하면 클라우드 서버를 이용할 수 있습니다. 클라우드를 어렵게 생각할 필요가 없습니다.기존 PC나 서버실과 같은 물리적인 하드웨어가 아닌 가상환경에서 원하는 스펙의 서버를 사용료를 지불하고 이용한다고 생각하면 될 것 같습니다.가장 중요한건! 클라우드 서비스를 어떻게 활용하는가?에 중점을 두어야 합니다.2. putty와 fileZila로 cloud 서버 접속 및 파일 전송하는 방법 윈도우 pc를 사용하는 저는 다른 리눅스 서버에 접속하기 위한 putty와 FTP방식으로 파일을 주고 받을 수 있는 filezilla를 자주 사용합니다.서버, ssh, 원격, FTP, SFTP 등의 개념들을 모른다면..이창을 끄고 공부하고 오길 바랍니다. 기회가 되면 해당 post에 대해 자세히 다뤄보도록 하겠습니다.putty로 cloud 서버 접속 서버 접속용 공인 IP 입력 포트포워딩 설정에서 외부포트로 설정한 port를 입력 SSH 선택 Open 창이 열리면 위 cloud 서버 생성시 생성했던 계정과 비밀번호를 입력 후 접속자! 접속했습니다. 엄청 간단하죠? putty는 ssh로 클라우드 리눅스 서버로 접속하는 프로그램입니다. 윈도우 -&amp;gt; 윈도우 로 연결할 때는 원격데스크탑을 이용하는 것과 같습니다.filezilla로 cloud 서버 접속putty와 같은 ssh 프로토콜로 접속하는 것이기 때문에 서버 접속용 공인 IP 입력 포트포워딩 설정에서 외부포트로 설정한 port를 입력 SFTP - SSH File Transfer Protocol 선택 cloud 서버 생성시 생성했던 계정과 비밀번호를 입력 연결이제 cloud서버에 접속해서 app을 배포할 준비가 완료되었습니다! 다음 포스트는 cloud 서버에 docker container 환경을 구축하여 python app을 배포하는 내용으로 찾아뵙겠습니다." }, { "title": "[python] 동기/비동기 프로그래밍의 이해", "url": "/posts/python-async/", "categories": "Python", "tags": "Python, Back-End, Synchronous, Asynchronous", "date": "2021-11-03 00:00:00 +0900", "snippet": "프론트엔드 개발자라면 JS의 async/await를 들어봤거나, 구현해본 경험이 있을 겁니다.python 3.5에서도 async/await 문법이 생기면서, 별도의 라이브러리 사용없이 비동기 프로그래밍이 가능해졌습니다.최근에 FastAPI로 REST-API 서버를 구축하는 업무를 맡게되면서 서비스로직을 비동기로 처리해야 할 상황이 생겼습니다.먼저 동기/비동기가 무엇인지, python에서 어떻게 사용하는지 알아보며 더 나아가 고수준의 API를 제공하는 concurrent.futures 모듈에 대해서 다뤄보도록 하겠습니다.동기(synchronous) 프로그래밍동시에 일어난다는 뜻으로, 요청과 결과가 동시에 일어난다는 의미입니다. 요청이 들어오면 시간이 얼마나 걸리던 결과를 return을 해주어야 합니다.동기 프로그래밍은 요청에 따른 결과를 반드시 return 해줘야할 때 사용합니다.기본적으로 python에서 사용하는 함수는 모두 동기프로그래밍입니다.아래 request_func() 함수는 synchronous_programming() 함수를 호출하여 리턴값을 받게 되는데 이는 호출과 동시에 함수에서 리턴해주는 결과 ‘return value’를 꼭 받아야지만 아래 print(result)가 실행됩니다. 만약 synchronous_programming() 에서 리턴을 1시간 후에 한다면, 요청한 client는 1시간을 기다려야 됩니다. def synchronous_programming(): return &#39;return value&#39; def request_func(): result = synchronous_programming() print(result)비동기(Asynchronous) 프로그래밍꼭 요청에 대한 결과를 기다려서 받아야 합니까? 그것을 해결해주는 것이 바로 비동기 프로그래밍입니다.동기 프로그램과 반대로, 요청과 결과가 동시에 일어나지 않아도 됩니다. 결과가 얼마나 걸리든 그 시간동안 다른 작업을 할 수 있으므로 자원을 효율적으로 사용할 수 있는 장점이 있습니다.python에서 사용하는 방법은 def 문법앞에 async를 붙이면 비동기 함수로 작동하게 됩니다.파이썬에서는 async가 붙은 함수를 코루틴(coroutine)라고도 부르는데, 동기 함수와 동일하게 호출하면 코루틴(coroutine) 객체로 리턴됩니다.따라서, async def 함수는 async로 선언된 다른 비동기 함수에 await를 붙여 사용합니다. js에서 async/await 호출 방식과 비슷한 원리입니다.(안다는 가정하에 넘어가겠습니다.)import timeimport asyncioasync def async_func1(): print(&#39;== async_func1 started ==&#39;) await asyncio.sleep(5) print(&#39;== async_func1 end ==&#39;) return &#39;async_func1&#39;async def async_func2(): print(&#39;== async_func2 started ==&#39;) await asyncio.sleep(3) print(&#39;== async_func2 end ==&#39;) return &#39;async_func2&#39;async def async_func3(): print(&#39;== async_func3 started ==&#39;) await asyncio.sleep(1) print(&#39;== async_func3 end ==&#39;) return &#39;async_func3&#39;async def root(): start = time.time() futures = [async_func1(), async_func2(), async_func3()] res1, res2, res3 = await asyncio.gather(*futures) end = time.time() print(&#39;비동기 처리 시간 : {}&#39;.format(round(end-start))) return {&quot;res1&quot;:res1, &quot;res2&quot;:res2, &quot;res3&quot;:res3}result = asyncio.run(root())print(result)실행결과를 보면 실행순서는async_func1() -&amp;gt; async_func2() -&amp;gt; async_func3()종료순서는 실행순서와 반대로 끝나는 것을 확인할 수 있다.async_func3() -&amp;gt; async_func2() -&amp;gt; async_func1()== async_func1 started ==== async_func2 started ==== async_func3 started ==== async_func3 end ==== async_func2 end ==== async_func1 end ==비동기 처리 시간 : 5{&#39;res1&#39;: &#39;async_func1&#39;, &#39;res2&#39;: &#39;async_func2&#39;, &#39;res3&#39;: &#39;async_func3&#39;}코드 순서를 자세히 살펴보면 최초 root() 함수를 run(실행) root() -&amp;gt; 시작은 async_func1(), async_func2(), async_func3() 순서대로 비동기로 실행 async_func3() 함수는 1초후 종료 async_func2() 함수는 3초후 종료 async_func1() 함수는 5초후 종료 모든 비동기 함수가 종료되는 시간은 5초동기프로그래밍으로 작성하게 되면async_func1() 5초 후 종료 -&amp;gt; async_func2() 3초 후 종료 -&amp;gt; async_func3() 1초 후 종료= 총 소요시간 : 9초간단한 예제를 통해 파이썬에서 제공하는 async/await 문법을 사용해서 비동기프로그래밍을 테스트해봤습니다.여기서 알 수 있듯이, 병렬적으로 자원을 사용하기 때문에 동기프로그래밍보다 효율적인 장점이 있습니다.다음 포스트에서는 높은 수준의 API를 제공하는 concurrent.futures 비동기 모듈을 다뤄보도록 하겠습니다." }, { "title": "01.Three.js 이해", "url": "/posts/three.js-chapter01/", "categories": "three.js", "tags": "Three.js, javascript, front-end, js, 3D, WebGL", "date": "2021-10-28 00:00:00 +0900", "snippet": "Three.js란 무엇인가?Three.js는 웹페이지에서 3차원 그래픽을 표현할 수 있도록 도와주는 자바스크립트 라이브러리, APIThree.js는 특정 웹 브라우저나 플러그인에 의존하지 않고 자바스크립트 언어를 사용하여 웹 컨텐츠의 한 공간을 GPU에서 가속되는 3차원 컨텐츠를 만들 수 있도록 도와준다.이를 가능하게 된 배경에는 WebGl 의 출현으로 가능하게 되었다.Three.js에서 WebGL의 이해가 중요한 것 같다. 밑에서 WebGL에 대해서 알아보자.WebGL이란 무엇인가?WebGL은 Web Graphics Library의 약자로 웹상에서 2D 및 3D 그래픽을 렌더링하기 위한 로우 레벨 Javascript API이다. OpenGL ES 2.0을 기반으로 브라우저 엔진에 내장된 HTML5 Canvas 요소 위에 그려진다.WebGL에 대해 잘 정리된 블로그를 참조했다.WebGL의 장점 로열티 없이 누구나 사용 가능하다. 렌더링 가속화를 지원하는 그래픽 하드웨어(그래픽 카드 등)을 활용한다. 별도의 플로그인이 필요 없으며, 웹 브라우저에 내장되어 실행된다. OpenGL ES 2.0을 기반으로하므로, 이미 OpenGL API에 대한 경험이 있다면 다루기가 쉽다. 자바스크립트 프로그래밍이 가능하다. 자바스크립트는 자동 메모리 관리를 지원하기 때문에 메모리를 수동으로 할당할 필요도 없고 WebGL이 자바스크립트의 기능을 상속 받는다. 모바일 브라우저에서도 사용 가능하다(모든 모바일 브라우저를 의미하진 않습니다) 정리하자면, WebGL 을 지원하는 브라우저에서 사용가능하며, 자바스크립트로 프로그래밍이 가능한게 큰 매력인 것 같다. 스마트팩토리를 하는 나의 경우에는 실제 공장의 공간을 비슷하게 구현하여 웹에서 3D로 모니터링을 할 수 있도록 사용하면 좋을 것 같다.렌더링(Rendering)렌더링은 컴퓨터 프로그램을 사용하여 모델에서 이미지를 생성하는 프로세스이다. 렌더링 유형은 아래와 같다. 소프트웨어 렌더링 모든 그래픽 계산을 CPU의 도움으로 처리 하드웨어 렌더링 모든 그래픽 계산을 GPU에 의해 수행 이 말은, 서버 사이드 렌더링과 클라이언트 사이드 렌더링을 통해 수행할 수 있다.즉, 서버 사이드 렌더링으로 GPU를 통해 렌더링을 하거나, 클라이언트 사이드 렌더링으로 CPU에서 로컬로 수행할 수 있다는 장점이 있다.브라우저의 WebGL 지원 여부 브라우저 지원여부 Mozilla Firefox 버전 4.0 이상 Google Chrome 버전 9 이상 Apple Safari 사파리 5.1 이상, 활성화 여부 확인 MS Edge 지원 internet explorer 지원안함, 하지만 IE11부터 마이크로소프트도 WebGL을 지원을 시작 Three.js는 구버전의 IE를 제외하고는 현재 모든 브라우저에서 제공된다고 보면 된다.준비물Three.js는 자바스크립트 라이브러리 이므로, 많은 준비물을 요구하지 않는다. TEXT 에디터 웹 브라우저 HTML, JS, CSSNEXT다음 시간에는 웹서버를 구축하고, Three.js를 직접 구현해 보도록 해보자. 웹서버 : python - FastAPI 웹브라우저 : Chrome" }, { "title": "CORS란 무엇이고, REST API에 어떻게 사용되는가?", "url": "/posts/web-cors/", "categories": "WEB, CORS", "tags": "WEB, CORS, API, HTTP, REST-API", "date": "2021-10-21 00:00:00 +0900", "snippet": "FastAPI로 REST API를 개발하던 도중 CORS라는 것을 접하게 되었다.회사에서 ‘프론트엔드’를 많이 다루다 보니 백엔드 관련 경험이 부족했다.이번 FastAPI를 개발하면서 여러가지 이슈와 개념들을 접하게 되었다.그중 하나가 CORS라는 개념이다.CORS란 무엇인가?교차 출처 리소스 공유(Cross-origin resource sharing, CORS), 교차 출처 자원 공유는 웹 페이지 상의 제한된 리소스를 최초 자원이 서비스된 도메인 밖의 다른 도메인으로부터 요청할 수 있게 허용하는 구조이다.사전정의 그대로 가져온 것이다. 교차 출처 리소스 공유?, 그리고 최초 자원이 서비스된 도메인 밖의 다른 도메인으로부터 요청할 수 있게 허용하는 구조?역시 정의대로 해석하려고하면 이해가 어렵다…잘 정리된 블로그를 보고 이해를 도왔다.참고 블로그 이동URL 구조CORS를 이해기 위해서는 출처(Origin) 라는 개념을 알아야한다.먼저 URL 구조를 살펴보자면, https://localhost:8080/user?page=1#Origin이란? Protocol Host Port(생략가능) Path Query String Fragment https localhost 8080 user pase=1 Origin이란? 출처란 URL 구조에서 Protocol, Host, Port를 합친 것을 말한다.동일 출처 정책(Same-Origin Policy)의 개념과 장점과 단점보통 API를 테스트할 때 Postman, swagger를 사용합니다. 해당 툴들을 이용할 땐 잘되다가, 브라우저를 통해 api를 호출하게 되면 CORS policy라는 오류가 발생할 때가 있다. 이거는 브라우저가 동일 출처 정책을 지키기 때문에 다른 출처의 리소스 접근을 금지하기 때문에 발생하는 것이다.동일 출처 정책의 장점은 XSS나 XSRF등의 보안 취약점을 노린 공격을 방어할 수 있다.동일 출처 정책의 단점은 외부 리소스를 사용할 수 없다.동일 출처 정책의 단점을 보완하기 위한 SOP의 예외 조항이 CORS이다.CORS의 동작원리단순 요청 방법(Simple request)단순 요청은 API를 요청하고, 서버는 Access-Control-Allow-Origin 헤더를 포함한 응답을 브라우저에게 보낸다. 브라우저는 Access-Control-Allow-Origin 헤더를 확인해서 CORS 동작을 작동할 지 판단하는 원리단순 요청 방법(Simple request) 조건 요청 메서드는 GET, HEAD, POST 중 하나여야만 한다. Accept, Accept-Language, Content-Language, Content-Type, DPR, Downlink, Save-Data, Viewport-Width, Width를 제외한 header를 사용하면 안 됩니다. Content-Type 헤더는 application/x-www-form-urlencoded, multipart/form-data, text/plain 중 하나를 사용해야 합니다.위의 2,3번 조건은 까다로운 편입니다. 2번 조건은 사용자 인증에 사용되는 Authorization 헤더를 사용하지 못하기 때문이고, 3번 조건은 대다수의 REST API들이 Content-Type으로 application/json를 사용하기 때문에 지키기 어렵다.예비 요청을 먼저 보내는 방법(Preflight request)GET, POST, PUT, DELETE 등의 메서드로 API를 요청하기 전에 OPTIONS라는 메서드를 통해 실제 요청을 전송할지 판단한다.OPTIONS 메서드로 서버에 예비 요청을 보낸뒤, 서버는 예비 요청에 대한 응답을 Access-Control-Allow-Origin 헤더를 포함하여 브라우저에게 보낸다. 브라우저는 단순 요청과 동일하게 Access-Control-Allow-Origin 헤더를 확인 후 CORS를 동작할 지 판단하는 원리이다.FastAPI로 개발된 REST API로 CORS 테스트! 현재 내가 위치한 브라우저는 ‘https://beomy.github.io’ 이다. 즉 ‘https://beomy.github.io’ 에서 API서버에 리소스를 요청한다고 생각해보자. REST API(GET) localhost:8000/user 호출 시 아래의 리소스를 리턴 [ { &quot;username&quot;: &quot;Rick&quot; }, { &quot;username&quot;: &quot;Morty&quot; }] 현재 내가 위치한 브라우저의 출처에서 API의 리소스를 요청하면 아래와 같이 Access-Control-Allow-Origin 헤더가 요청리소스에 포함되어 있지 않다라는 오류가 뜬다. FastAPI 서버에서 응답헤더에 Access-Control-Allow-Origin와 출처를 추가해준다. allow_methods=[“*“]은 Access-Control-Allow-Methods POST, GET, PUT, DELETE 모두 허용이고 allow_headers=[“*“]은 Access-Control-Allow-Headers 응답 헤더를 모두 허용하겠다는 의미이다. 다시 요청을 보내면 서버에서 리소스가 리턴되는 것을 확인할 수 있다. 개발자 도구 &amp;gt; Network에서 응답 헤더를 확인해보면 서버에서 Access-Control-Allow-Origin 헤더를 브라우저에 보낸것을 확인할 수 있다!.끝으로프론트엔드 개발자 입장에서 서버로 리소스를 요청할 때 CORS 에러가 발생한다면, 서버에 Access-Control-Allow-Origin 등 CORS를 해결하기 위한 몇 가지 응답 헤더를 포함해 달라고 요청한다는 것을 배웠다.Node.js, FastAPI 등의 대부분의 프레임워크에서 CORS 응답 헤더를 추가해 주기는 기능이 있어 간편하게 사용할 수 있지만, CORS가 무엇이고 해당 프레임워크의 지원이 없더라도 CORS 에러 문제가 발생할 때 발생원인과 어떻게 해결해야 되는지 알아보는 시간이었다." }, { "title": "API란 무엇이며, 좋은 API를 설계하기 위한 방법이 무엇일까?", "url": "/posts/restApi-api-define/", "categories": "WEB, REST-API", "tags": "WEB, REST-API, HTTP", "date": "2021-10-14 00:00:00 +0900", "snippet": "회사에서 naver cloud server와 Docker로 서비스 환경을 구축하고, 구축된 환경에 REST API를 개발 및 배포하는 작업을 맡게되었다.개발하기 앞서, 다음과 같은 질문을 던져보았다. REST란 무엇인가? REST API란 무엇인가? REST API 설계하는 방법1. REST란 무엇인가 ‘Representational State Transfer’의 약자로, 자원을 이름으로 구분하고 자원의 상태(정보)를 주고 받는 모든 것을 의미한다. 즉, 자원(resource)의 표현(representation) 에 의한 상태 전달(json, XML를 통해 데이터를 주고받는 것이 일반적)이다.정의대로 이해하려고하면 무슨말인지 이해가 어려울 수 있으니 더 쉽게 풀어보자면HTTP URI의 이름을 정하는것을 자원(resource)이라고 하고 HTTP Method(POST, GET, PUT, DELETE) 방식으로 CRUD 작업을 수행하는 것이다. (POST) localhost:8080/user –&amp;gt; user 정보를 등록 (GET) localhost:8080/user –&amp;gt; user 정보 조회 (PUT) localhost:8080/user –&amp;gt; user 정보 수정 (DELTE) localhost:8080/user –&amp;gt; user 정보 삭제=&amp;gt; “/user” 라는 자원(resource)을 Client가 POST(등록), GET(조회), PUT(수정), DELETE(삭제) 행위에 따라 요청하게 되면server는 이제 적절한 정보를 json, xml 등의 형태로 응답해주는 것을 REST이다.2. REST API란 무엇인가? API(Application Programming Interface)는 컴퓨터 프로그램간 상호작용을 촉진하며, 서로 정보를 교환하는 것 REST API란 위에 REST기반의 서비스를 API로 구현한 것을 말한다. 간단히 말해 REST형식으로 서비스를 구현하고, Client(app)에서 필요한 정보를 요청하면 알맞은 정보를 json 등의 형태로 정보를 리턴해주는 것을 말한다. 카카오맵, 구글맵, 공공데이터, 등 OpenApi를 제공하는 업체들은 대부분 REST API로 제공한다.3. REST API 설계 방법 URI를 보고 직관적으로 이해하기 쉽게 만들어야 한다. 자원(resource)은 동사보다는 명사를 사용한다. HTTPS Method의 POST, GET, PUT, DELETE의 행위를 리소스에 사용하지 않는다. 리소스간의 관계를 표현한다." }, { "title": "Getting Started", "url": "/posts/getting-started/", "categories": "Blogging, Tutorial", "tags": "getting started", "date": "2019-08-09 00:00:00 +0900", "snippet": "PrerequisitesFollow the instructions in the Jekyll Docs to complete the installation of Ruby, RubyGems, Jekyll, and Bundler.InstallationCreating a New SiteThere are two ways to create a new repository for this theme: Using the Chirpy Starter - Easy to upgrade, isolates irrelevant project files so you can focus on writing. Forking on GitHub - Convenient for custom development, but difficult to upgrade. Unless you are familiar with Jekyll and are determined to tweak or contribute to this project, this approach is not recommended.Option 1. Using the Chirpy StarterCreate a new repository from the Chirpy Starter and name it &amp;lt;GH_USERNAME&amp;gt;.github.io, where GH_USERNAME represents your GitHub username.Option 2. Forking on GitHubFork Chirpy on GitHub and rename it to &amp;lt;GH_USERNAME&amp;gt;.github.io. Please note that the default branch code is in development. If you want the site to be stable, please switch to the latest tag and start writing.And then execute:$ bash tools/init.sh Note: If you don’t want to deploy your site on GitHub Pages, append option --no-gh at the end of the above command.The above command will: Removes some files or directories from your repository: .travis.yml files under _posts folder docs If the option --no-gh is provided, the directory .github will be deleted. Otherwise, set up the GitHub Action workflow by removing the extension .hook of .github/workflows/pages-deploy.yml.hook, and then remove the other files and directories in the folder .github. Removes item Gemfile.lock from .gitignore. Creates a new commit to save the changes automatically.Installing DependenciesBefore running for the first time, go to the root directory of your site, and install dependencies as follows:$ bundleUsageConfigurationUpdate the variables of _config.yml as needed. Some of them are typical options: url avatar timezone langCustoming StylesheetIf you need to customize the stylesheet, copy the theme’s assets/css/style.scss to the same path on your Jekyll site, and then add the custom style at the end of the style file.Starting from v4.1.0, if you want to overwrite the SASS variables defined in _sass/addon/variables.scss, create a new file _sass/variables-hook.scss and assign new values to the target variable in it.Running Local ServerYou may want to preview the site contents before publishing, so just run it by:$ bundle exec jekyll sOr run the site on Docker with the following command:$ docker run -it --rm \\ --volume=&quot;$PWD:/srv/jekyll&quot; \\ -p 4000:4000 jekyll/jekyll \\ jekyll serveAfter a while, the local service will be published at http://127.0.0.1:4000.DeploymentBefore the deployment begins, check out the file _config.yml and make sure the url is configured correctly. Furthermore, if you prefer the project site and don’t use a custom domain, or you want to visit your website with a base URL on a web server other than GitHub Pages, remember to change the baseurl to your project name that starts with a slash, e.g, /project-name.Now you can choose ONE of the following methods to deploy your Jekyll site.Deploy by Using Github ActionsFor security reasons, GitHub Pages build runs on safe mode, which restricts us from using plugins to generate additional page files. Therefore, we can use GitHub Actions to build the site, store the built site files on a new branch, and use that branch as the source of the GitHub Pages service.Quickly check the files needed for GitHub Actions build: Ensure your Jekyll site has the file .github/workflows/pages-deploy.yml. Otherwise, create a new one and fill in the contents of the sample file, and the value of the on.push.branches should be the same as your repo’s default branch name. Ensure your Jekyll site has file tools/deploy.sh. Otherwise, copy it from here to your Jekyll site. Furthermore, if you have committed Gemfile.lock to the repo, and your runtime system is not Linux, don’t forget to update the platform list in the lock file: $ bundle lock --add-platform x86_64-linux After the above steps, rename your repository to &amp;lt;GH_USERNAME&amp;gt;.github.io on GitHub.Now publish your Jekyll site by: Push any commit to remote to trigger the GitHub Actions workflow. Once the build is complete and successful, a new remote branch named gh-pages will appear to store the built site files. Browse to your repository on GitHub. Select the tab Settings, then click Pages in the left navigation bar, and then in the section Source of GitHub Pages, select the /(root) directory of branch gh-pages as the publishing source. Remember to click Save before leaving. Visit your website at the address indicated by GitHub. Manually Build and DeployOn self-hosted servers, you cannot enjoy the convenience of GitHub Actions. Therefore, you should build the site on your local machine and then upload the site files to the server.Go to the root of the source project, and build your site as follows:$ JEKYLL_ENV=production bundle exec jekyll bOr build the site on Docker:$ docker run -it --rm \\ --env JEKYLL_ENV=production \\ --volume=&quot;$PWD:/srv/jekyll&quot; \\ jekyll/jekyll \\ jekyll buildUnless you specified the output path, the generated site files will be placed in folder _site of the project’s root directory. Now you should upload those files to the target server.UpgradingIt depends on how you use the theme: If you are using the theme gem (there will be gem &quot;jekyll-theme-chirpy&quot; in the Gemfile), editing the Gemfile and update the version number of the theme gem, for example: - gem &quot;jekyll-theme-chirpy&quot;, &quot;~&amp;gt; 3.2&quot;, &quot;&amp;gt;= 3.2.1&quot;+ gem &quot;jekyll-theme-chirpy&quot;, &quot;~&amp;gt; 3.3&quot;, &quot;&amp;gt;= 3.3.0&quot; And then execute the following command: $ bundle update jekyll-theme-chirpy As the version upgrades, the critical files (for details, see the Startup Template) and configuration options will change. Please refer to the Upgrade Guide to keep your repo’s files in sync with the latest version of the theme. If you forked from the source project (there will be gemspec in the Gemfile of your site), then merge the latest upstream tags into your Jekyll site to complete the upgrade.The merge is likely to conflict with your local modifications. Please be patient and careful to resolve these conflicts. The favicons of Chirpy are placed in the directory assets/img/favicons/. You may want to replace them with your own. The following sections will guide you to create and replace the default favicons.Generate the faviconPrepare a square image (PNG, JPG, or SVG) with a size of 512x512 or more, and then go to the online tool Real Favicon Generator and click the button Select your Favicon image to upload your image file.In the next step, the webpage will show all usage scenarios. You can keep the default options, scroll to the bottom of the page, and click the button Generate your Favicons and HTML code to generate the favicon.Download &amp;amp; ReplaceDownload the generated package, unzip and delete the following two from the extracted files: browserconfig.xml site.webmanifestNow, copy the remaining image files (PNG and ICO) to cover the original files in the folder assets/img/favicons/ of your Jekyll site. If your Jekyll site doesn’t have this directory yet, just create one.The following table will help you understand the changes to the favicon files: File(s) From Online Tool From Chirpy *.PNG ✓ ✗ *.ICO ✓ ✗ browserconfig.xml ✗ ✓ site.webmanifest ✗ ✓ Note: ✓ means keep, ✗ means delete.The next time you build the site, the favicon will be replaced with a customized edition.Setup Google Analytics superProxy Clone the Google Analytics superProxy project on Github: https://github.com/googleanalytics/google-analytics-super-proxy to your local. Remove the first 2 lines in the src/app.yaml file: - application: your-project-id- version: 1 In src/config.py, add the OAUTH_CLIENT_ID and OAUTH_CLIENT_SECRET that you gathered from your App Engine Dashboard. Enter any random key for XSRF_KEY, your config.py should look similar to this #!/usr/bin/python2.7__author__ = &#39;pete.frisella@gmail.com (Pete Frisella)&#39;# OAuth 2.0 Client SettingsAUTH_CONFIG = { &#39;OAUTH_CLIENT_ID&#39;: &#39;YOUR_CLIENT_ID&#39;, &#39;OAUTH_CLIENT_SECRET&#39;: &#39;YOUR_CLIENT_SECRET&#39;, &#39;OAUTH_REDIRECT_URI&#39;: &#39;%s%s&#39; % ( &#39;https://chirpy-test-XXXXXX.ue.r.appspot.com&#39;, &#39;/admin/auth&#39; )}# XSRF SettingsXSRF_KEY = &#39;OnceUponATimeThereLivedALegend&#39; Tip: You can configure a custom domain instead of https://PROJECT_ID.REGION_ID.r.appspot.com. But, for the sake of keeping it simple, we will be using the Google provided default URL. From inside the src/ directory, deploy the app [root@bc96abf71ef8 src]# gcloud app deployServices to deploy:descriptor: [/tmp/google-analytics-super-proxy/src/app.yaml]source: [/tmp/google-analytics-super-proxy/src]target project: [chirpy-test-XXXX]target service: [default]target version: [VESRION_NUM]target url: [https://chirpy-test-XXXX.ue.r.appspot.com]Do you want to continue (Y/n)? YBeginning deployment of service [default]...╔════════════════════════════════════════════════════════════╗╠═ Uploading 1 file to Google Cloud Storage ═╣╚════════════════════════════════════════════════════════════╝File upload done.Updating service [default]...done.Setting traffic split for service [default]...done.Deployed service [default] to [https://chirpy-test-XXXX.ue.r.appspot.com]You can stream logs from the command line by running:$ gcloud app logs tail -s defaultTo view your application in the web browser run:$ gcloud app browse Visit the deployed service. Add a /admin to the end of the URL. Click on Authorize Users and make sure to add yourself as a managed user. If you get any errors, please Google it. The errors are self-explanatory and should be easy to fix.If everything went good, you’ll get this screen:" }, { "title": "Text and Typography", "url": "/posts/text-and-typography/", "categories": "Blogging, Demo", "tags": "typography", "date": "2019-08-08 00:00:00 +0900", "snippet": "This post is to show Markdown syntax rendering on Chirpy, you can also use it as an example of writing. Now, let’s start looking at text and typography.TitlesH1 - headingH2 - headingH3 - headingH4 - headingParagraphI wandered lonely as a cloudThat floats on high o’er vales and hills,When all at once I saw a crowd,A host, of golden daffodils;Beside the lake, beneath the trees,Fluttering and dancing in the breeze.ListsOrdered list Firstly Secondly ThirdlyUnordered list Chapter Section Paragraph Task list TODO Completed Defeat COVID-19 Vaccine production Economic recovery People smile again Description list Sun the star around which the earth orbits Moon the natural satellite of the earth, visible by reflected light from the sunBlock Quote This line to shows the Block Quote.Tables Company Contact Country Alfreds Futterkiste Maria Anders Germany Island Trading Helen Bennett UK Magazzini Alimentari Riuniti Giovanni Rovelli Italy Linkshttp://127.0.0.1:4000FootnoteClick the hook will locate the footnote1, and here is another footnote2.Images Default (with caption)Full screen width and center alignment Shadowshadow effect (visible in light mode) Left aligned Float to left “A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space.” Float to right “A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space. A repetitive and meaningless text is used to fill the space.” Mermaid SVG gantt title Adding GANTT diagram functionality to mermaid apple :a, 2017-07-20, 1w banana :crit, b, 2017-07-23, 1d cherry :active, c, after b a, 1dMathematicsThe mathematics powered by MathJax:\\[\\sum_{n=1}^\\infty 1/n^2 = \\frac{\\pi^2}{6}\\]When $a \\ne 0$, there are two solutions to $ax^2 + bx + c = 0$ and they are\\[x = {-b \\pm \\sqrt{b^2-4ac} \\over 2a}\\]Inline codeThis is an example of Inline Code.Code blockCommonThis is a common code snippet, without syntax highlight and line number.Specific LanguagesConsole$ env |grep SHELLSHELL=/usr/local/bin/bashPYENV_SHELL=bashShellif [ $? -ne 0 ]; then echo &quot;The command was not successful.&quot;; #do the needful / exitfi;Specific filename@import &quot;colors/light-typography&quot;, &quot;colors/dark-typography&quot;Reverse Footnote The footnote source &amp;#8617; The 2nd footnote source &amp;#8617; " } ]
